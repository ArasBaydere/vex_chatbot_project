import google.generativeai as genai
import faiss
import numpy as np
import os
import json
import re
from functools import lru_cache

# TÃ¼rkÃ§e-Ä°ngilizce keyword mapping
TURKISH_ENGLISH_KEYWORDS = {
    # Robot ve boyut terimleri
    'robot': 'robot',
    'boyut': 'size',
    'boyutlar': 'dimensions',
    'boyutlarÄ±': 'dimensions', 
    'Ã¶lÃ§Ã¼': 'size',
    'Ã¶lÃ§Ã¼ler': 'dimensions',
    'Ã¶lÃ§Ã¼leri': 'dimensions',
    'sÄ±nÄ±r': 'limit',
    'sÄ±nÄ±rÄ±': 'limit',
    'sÄ±nÄ±rlar': 'limits',
    'sÄ±nÄ±rlarÄ±': 'limits',
    'aÄŸÄ±rlÄ±k': 'weight',
    'maksimum': 'maximum',
    'minimum': 'minimum',
    'geniÅŸleme': 'expansion',
    'hacim': 'volume',
    'kÃ¼bik': 'cubic',
    'inÃ§': 'inch',
    'santimetre': 'centimeter',
    'milimetre': 'millimeter',
    
    # Malzeme terimleri
    'plastik': 'plastic',
    'polikarbonat': 'polycarbonate',
    'polikarbonate': 'polycarbonate',
    'Ã¶zel': 'custom',
    'malzeme': 'material',
    'metal': 'metal',
    'parÃ§a': 'part',
    'parÃ§alar': 'parts',
    'bileÅŸen': 'component',
    'miktarda': 'amount',
    'miktar': 'amount',
    'sÄ±nÄ±rlÄ±': 'limited',
    'izin': 'allowed',
    'yasak': 'illegal',
    
    # Oyun terimleri
    'oyun': 'game',
    'maÃ§': 'match',
    'mÃ¼sabaka': 'competition',
    'turnuva': 'tournament',
    'puan': 'point',
    'skor': 'score',
    'gol': 'goal',
    'hedef': 'target',
    
    # Kural terimleri
    'kural': 'rule',
    'kurallar': 'rules',
    'yasak': 'illegal',
    'izin': 'legal',
    'ceza': 'penalty',
    'ihlal': 'violation',
    
    # Teknik terimler
    'motor': 'motor',
    'gÃ¼Ã§': 'power',
    'batarya': 'battery',
    'sensÃ¶r': 'sensor',
    'program': 'program',
    'otonom': 'autonomous',
    'manuel': 'manual',
    'kontrol': 'control',
    'kumanda': 'control'
}

def translate_query_keywords(query):
    """
    TÃ¼rkÃ§e sorguyu Ä°ngilizce anahtar kelimelerle zenginleÅŸtir
    """
    query_lower = query.lower()
    translated_terms = []
    
    for turkish, english in TURKISH_ENGLISH_KEYWORDS.items():
        if turkish in query_lower:
            translated_terms.append(english)
    
    # Orijinal sorgu + Ä°ngilizce terimler
    enhanced_query = query + " " + " ".join(translated_terms)
    return enhanced_query

# Proje ana dizininden Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nÄ± varsayalÄ±m
script_dir = os.path.dirname(os.path.abspath(__file__))
chunks_path = os.path.join(script_dir, "..", "data", "processed_chunks.json")
faiss_index_path = os.path.join(script_dir, "..", "data", "faiss_index.bin")

# API AnahtarÄ±nÄ± Ã§evre deÄŸiÅŸkeninden al
API_KEY = os.getenv("GOOGLE_API_KEY", "your_api_key_here")
genai.configure(api_key=API_KEY)

# FAISS indeksini ve metin parÃ§alarÄ±nÄ± bir kere yÃ¼kle ve Ã¶nbelleÄŸe al
@lru_cache(maxsize=1)
def load_data():
    try:
        index = faiss.read_index(faiss_index_path)
        with open(chunks_path, 'r', encoding='utf-8') as f:
            chunks = json.load(f)
        print("FAISS indeksi ve metin parÃ§alarÄ± baÅŸarÄ±yla yÃ¼klendi.")
        return index, chunks
    except Exception as e:
        print(f"Hata: VeritabanÄ± dosyalarÄ± yÃ¼klenemedi. Hata: {e}")
        return None, None

def get_related_chunks(query, k=30):
    """
    KullanÄ±cÄ± sorgusuyla en alakalÄ± metin parÃ§alarÄ±nÄ± ve meta verilerini geri getirir.
    Daha geniÅŸ bir arama havuzundan kelime tabanlÄ± filtreleme yapar.
    
    Args:
        query (str): KullanÄ±cÄ± sorgusu.
        k (int): Geri getirilecek en alakalÄ± parÃ§a sayÄ±sÄ±.
        
    Returns:
        list: En alakalÄ± metin parÃ§alarÄ±nÄ±n {'content', 'page_number', 'rule_id'} formatÄ±nda listesi.
    """
    index, chunks = load_data()
    if not index or not chunks:
        print("HATA: Index veya chunks yÃ¼klenemedi!")
        return []

    print(f"\n=== DETAYLI DEBUG BAÅLANGICI ===")
    print(f"Orijinal sorgu: '{query}'")
    
    # TÃ¼rkÃ§e sorguyu Ä°ngilizce terimlerle zenginleÅŸtir
    enhanced_query = translate_query_keywords(query)
    print(f"ZenginleÅŸtirilmiÅŸ sorgu: '{enhanced_query}'")
    print(f"Toplam chunk sayÄ±sÄ±: {len(chunks)}")
    
    # Enhanced query ile sorguyu vektÃ¶rleÅŸtirme
    try:
        query_embedding = genai.embed_content(
            model='models/text-embedding-004', 
            content=enhanced_query,
            task_type="retrieval_query"
        )['embedding']
        query_embedding_np = np.array([query_embedding], dtype='float32')
        print(f"Query embedding baÅŸarÄ±yla oluÅŸturuldu, boyut: {len(query_embedding)}")
    except Exception as e:
        print(f"HATA: Query embedding oluÅŸturulamadÄ±: {e}")
        # API baÅŸarÄ±sÄ±z olursa, enhanced query ile anahtar kelime aramasÄ± yap
        return keyword_only_search(enhanced_query, chunks)

    # FAISS'te en yakÄ±n komÅŸularÄ± arama
    try:
        distances, indices = index.search(query_embedding_np, k)
        print(f"FAISS arama tamamlandÄ±, {len(indices[0])} sonuÃ§ bulundu")
        print(f"Ä°lk 5 distance: {distances[0][:5]}")
        print(f"Ä°lk 5 index: {indices[0][:5]}")
    except Exception as e:
        print(f"HATA: FAISS arama baÅŸarÄ±sÄ±z: {e}")
        return keyword_only_search(enhanced_query, chunks)
    
    retrieved_chunks = []
    for i, idx in enumerate(indices[0]):
        if idx < len(chunks):
            chunk = {'content': chunks[idx]['content'], 'page_number': chunks[idx]['page_number'], 'rule_id': chunks[idx]['rule_id']}
            retrieved_chunks.append(chunk)
            if i < 5:  # Ä°lk 5 chunk'Ä± debug iÃ§in gÃ¶ster
                print(f"Chunk {i}: Sayfa {chunk['page_number']}, Kural {chunk['rule_id']}")
                print(f"Ä°Ã§erik Ã¶zeti: {chunk['content'][:200]}...")
                print("---")

    # Anahtar kelimelerle ikincil filtreleme - daha kapsamlÄ± kelime setleri
    # Hem orijinal sorgu hem de enhanced query'yi anahtar kelime belirlemede kullan
    combined_query = (query + " " + enhanced_query).lower()
    keywords = []
    
    # Boyut/Ã¶lÃ§Ã¼ sorularÄ± iÃ§in
    if any(w in combined_query for w in ['boyut', 'size', 'Ã¶lÃ§Ã¼', 'limit', 'sÄ±nÄ±r', 'dimension', 'Ã¶lÃ§Ã¼ler', 'bÃ¼yÃ¼klÃ¼k', 'dimensions']):
        keywords.extend(['boyut', 'size', 'Ã¶lÃ§Ã¼', 'limit', 'sÄ±nÄ±r', 'dimension', 'dimensions', 'expansion', 'geniÅŸleme', 
                        '18', '22', 'inch', 'inÃ§', 'mm', 'volume', 'hacim', 'cubic', 'kÃ¼bik'])
        print("ğŸ” Boyut sorgusu algÄ±landÄ±")
        
    # AÄŸÄ±rlÄ±k sorularÄ± iÃ§in  
    elif any(w in combined_query for w in ['aÄŸÄ±rlÄ±k', 'weight', 'gram', 'kg', 'kilogram', 'kaÃ§', 'ne kadar']):
        keywords.extend(['aÄŸÄ±rlÄ±k', 'weight', 'gram', 'kg', 'kilogram', 'mass', 'kÃ¼tle', 'block', 'blok', 
                        '40', 'approximately', 'yaklaÅŸÄ±k'])
        print("âš–ï¸ AÄŸÄ±rlÄ±k sorgusu algÄ±landÄ±")
        
    # Malzeme/plastik sorularÄ± iÃ§in
    elif any(w in combined_query for w in ['plastik', 'plastic', 'polikarbonat', 'polycarbonate', 'malzeme', 'material', 'Ã¶zel', 'custom', 'parÃ§a', 'part']):
        keywords.extend(['plastic', 'plastik', 'polycarbonate', 'polikarbonat', 'material', 'malzeme', 'custom', 'Ã¶zel', 
                        'part', 'parÃ§a', 'component', 'bileÅŸen', 'allowed', 'izin', 'limited', 'sÄ±nÄ±rlÄ±', 'amount', 'miktar', 'R25'])
        print("ğŸ§ª Malzeme sorgusu algÄ±landÄ±")
        
    # Kural numarasÄ± sorularÄ± iÃ§in (R1, R25, SG1 vb.)
    elif any(re.search(r'\b[RSG]+\d+\b', combined_query) for w in [combined_query]):
        # Kural numarasÄ±nÄ± Ã§Ä±kar
        rule_matches = re.findall(r'\b[RSG]+\d+\b', combined_query.upper())
        keywords.extend(rule_matches)
        keywords.extend(['rule', 'kural', 'regulation'])
        print(f"ğŸ“‹ Kural numarasÄ± sorgusu algÄ±landÄ±: {rule_matches}")
        
    # Robot sorularÄ± iÃ§in
    elif 'robot' in combined_query:
        keywords.extend(['robot', 'robotics', 'competition', 'yarÄ±ÅŸma'])
        print("ğŸ¤– Robot sorgusu algÄ±landÄ±")
    
    # Hem orijinal hem enhanced query'deki kelimeleri anahtar kelimelere ekle
    combined_words = re.findall(r'\b\w{2,}\b', combined_query)  # 2+ karakter kelimeler
    keywords.extend(combined_words)
    
    # Temel anahtar kelimeler her zaman dahil
    keywords.extend(["rule", "kural", "regulation", "kural"])
    
    # Duplicate'larÄ± kaldÄ±r
    keywords = list(set(keywords))
    print(f"Anahtar kelimeler: {keywords}")

    filtered_chunks = []
    for chunk in retrieved_chunks:
        content_lower = chunk['content'].lower()
        rule_id_lower = chunk['rule_id'].lower()
        
        # Her anahtar kelime iÃ§in ayrÄ± ayrÄ± kontrol et
        matched_keywords = []
        for keyword in keywords:
            # Daha esnek eÅŸleÅŸtirme
            if (keyword in content_lower or keyword in rule_id_lower or
                re.search(r'\b' + re.escape(keyword) + r'\b', content_lower) or
                re.search(r'\b' + re.escape(keyword) + r'\b', rule_id_lower)):
                matched_keywords.append(keyword)
        
        if matched_keywords:
            chunk['matched_keywords'] = matched_keywords
            filtered_chunks.append(chunk)
            print(f"âœ“ EÅLEÅME: Sayfa {chunk['page_number']}, Kural {chunk['rule_id']}, Kelimeler: {matched_keywords}")

    print(f"Filtreleme sonrasÄ± chunk sayÄ±sÄ±: {len(filtered_chunks)}")

    # EÄŸer filtreleme sonucunda parÃ§a bulunamazsa, en Ã¼stteki 5 taneyi kullan
    if not filtered_chunks:
        print("âš ï¸ HiÃ§ eÅŸleÅŸme bulunamadÄ±, ilk 5 chunk kullanÄ±lacak")
        final_chunks_to_use = retrieved_chunks[:5]
    else:
        final_chunks_to_use = filtered_chunks[:5]
    
    print(f"\n--- FINAL CHUNKS ({len(final_chunks_to_use)} adet) ---")
    for i, chunk in enumerate(final_chunks_to_use):
        print(f"{i+1}. Sayfa: {chunk['page_number']}, Kural: {chunk['rule_id']}")
        if 'matched_keywords' in chunk:
            print(f"   EÅŸleÅŸen kelimeler: {chunk['matched_keywords']}")
        print(f"   Ä°Ã§erik: {chunk['content'][:150]}...")
        print("")
    print("=== DETAYLI DEBUG SONU ===\n")

    return final_chunks_to_use

def keyword_only_search(query, chunks):
    """API baÅŸarÄ±sÄ±z olduÄŸunda sadece anahtar kelime aramasÄ± yapar."""
    print("ğŸ”„ API baÅŸarÄ±sÄ±z, anahtar kelime aramasÄ±na geÃ§iliyor...")
    
    query_lower = query.lower()
    keywords = []
    
    # Boyut sorularÄ±
    if any(w in query_lower for w in ['boyut', 'size', 'Ã¶lÃ§Ã¼', 'limit', 'sÄ±nÄ±r']):
        keywords.extend(['18', '22', 'inch', 'expansion', 'size', 'dimension', 'boyut', 'geniÅŸleme'])
        
    # AÄŸÄ±rlÄ±k sorularÄ±
    elif any(w in query_lower for w in ['aÄŸÄ±rlÄ±k', 'weight', 'gram']):
        keywords.extend(['40', 'gram', 'weight', 'block', 'aÄŸÄ±rlÄ±k'])
        
    # Sorgu kelimelerini ekle
    keywords.extend(re.findall(r'\b\w{2,}\b', query_lower))
    
    matching_chunks = []
    for chunk in chunks:
        content_lower = chunk['content'].lower()
        score = 0
        
        for keyword in keywords:
            if keyword in content_lower:
                score += 1
                
        if score > 0:
            chunk_copy = chunk.copy()
            chunk_copy['score'] = score
            matching_chunks.append(chunk_copy)
    
    # Score'a gÃ¶re sÄ±rala
    matching_chunks.sort(key=lambda x: x['score'], reverse=True)
    
    print(f"Anahtar kelime aramasÄ±: {len(matching_chunks)} chunk bulundu")
    return matching_chunks[:5]

def create_rag_prompt(query, related_chunks_with_metadata, history=None):
    """
    Gemini modeline gÃ¶nderilecek nihai prompt'u oluÅŸturur.
    
    Args:
        query (str): KullanÄ±cÄ± sorgusu.
        related_chunks_with_metadata (list): En alakalÄ± metin parÃ§alarÄ±nÄ±n ve meta verilerinin listesi.
        history (list): Sohbet geÃ§miÅŸi (opsiyonel).
        
    Returns:
        str: Gemini'ye gÃ¶nderilecek prompt.
    """
    
    system_prompt = (
        "Sen, VEX Robotics 2025-2026 oyunu 'Push Back' konusunda uzman, yardÄ±msever bir yapay zeka asistanÄ±sÄ±n. "
        "AmacÄ±n, VEX takÄ±mlarÄ±na oyun kÄ±lavuzuyla ilgili sorduklarÄ± sorulara hÄ±zlÄ± ve doÄŸru cevaplar vermektir.\n\n"
        "Ã‡ok Ã¶nemli: CevaplarÄ±nÄ± SADECE sana sunulan 'KAYNAK METÄ°NLER' bÃ¶lÃ¼mÃ¼ndeki bilgilere dayanarak, direkt ve doÄŸru bir ÅŸekilde oluÅŸtur.\n"
        "Her cevabÄ±nÄ±n sonuna, cevabÄ± aldÄ±ÄŸÄ±n kuralÄ± ve sayfa numarasÄ±nÄ± **(Kaynak: Sayfa X, Kural Y)** formatÄ±nda mutlaka ekle.\n"
        "EÄŸer sorunun cevabÄ± sana verilen kaynak metinlerde yoksa, ÅŸu formatta cevap ver:\n"
        "'Bu bilgi 2025-2026 Push Back oyun kÄ±lavuzunda mevcut deÄŸil. Ancak ÅŸu benzer bilgiler var: [benzer kural varsa belirt]'\n\n"
        "Ã–zel durumlar:\n"
        "- Robot aÄŸÄ±rlÄ±k sÄ±nÄ±rÄ± sorulursa: '2025-2026 Push Back oyununda robot aÄŸÄ±rlÄ±k sÄ±nÄ±rÄ± belirtilmemiÅŸ. Sadece boyut sÄ±nÄ±rlarÄ± var.'\n"
        "- Robot boyut/Ã¶lÃ§Ã¼ sorulursa: SG1, SG2, SG3 kurallarÄ±ndan cevap ver.\n"
        "- Plastik/malzeme sorulursa: R25 kuralÄ±ndan tam detaylarÄ± ver. 'A limited amount of custom plastic is allowed' gibi kÄ±sa cevaplar verme, mÃ¼mkÃ¼nse ek kurallarÄ± da belirt.\n"
        "- Polikarbonat sorulursa: Polycarbonate panels field perimeter decorations iÃ§in kullanÄ±labilir.\n\n"
        "CevaplarÄ±nda VEX jargonunu kullanmaktan Ã§ekinme ve her zaman yardÄ±m odaklÄ±, arkadaÅŸ canlÄ±sÄ± bir dil kullan."
    )
    
    # RAG ile bulunan ilgili kurallarÄ± prompt'a ekliyoruz, meta verileriyle birlikte.
    context = "\n\nKAYNAK METÄ°NLER:\n"
    for chunk in related_chunks_with_metadata:
        context += f"--- Sayfa {chunk['page_number']}, Kural {chunk['rule_id']}:\n{chunk['content']}\n\n"
    
    # Sohbet geÃ§miÅŸini ekliyoruz
    history_str = ""
    if history:
        for turn in history:
            history_str += f"\nKullanÄ±cÄ±: {turn['user']}\nAsistan: {turn['model']}\n"
    
    final_prompt = f"{system_prompt}{history_str}{context}\n\nKullanÄ±cÄ±: {query}\nAsistan:"
    
    return final_prompt

def get_answer_from_gemini(query):
    """
    KullanÄ±cÄ± sorgusuna RAG mimarisiyle cevap Ã¼retir.
    
    Args:
        query (str): KullanÄ±cÄ± sorgusu.
        
    Returns:
        str: Gemini modelinden gelen cevap.
    """
    if not load_data()[0] or not load_data()[1]:
        return "ÃœzgÃ¼nÃ¼m, RAG veritabanÄ± yÃ¼klenemedi. LÃ¼tfen sistem yÃ¶neticinizle iletiÅŸime geÃ§in."

    try:
        related_chunks_with_metadata = get_related_chunks(query)
        
        if not related_chunks_with_metadata:
            return "ÃœzgÃ¼nÃ¼m, sorgunuzla ilgili bilgi bulunamadÄ±. LÃ¼tfen farklÄ± kelimelerle tekrar deneyin."
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        final_prompt = create_rag_prompt(query, related_chunks_with_metadata)
        
        print(f"\nğŸ¤– Gemini'ye gÃ¶nderilen prompt uzunluÄŸu: {len(final_prompt)} karakter")
        
        # Timeout ve retry ile API Ã§aÄŸrÄ±sÄ±
        import time
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ Gemini API Ã§aÄŸrÄ±sÄ± (deneme {attempt + 1}/{max_retries})...")
                
                response = model.generate_content(
                    final_prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.1,  # Daha tutarlÄ± cevaplar iÃ§in
                        max_output_tokens=1000,
                    )
                )
                
                if response and response.text:
                    print("âœ… Gemini API baÅŸarÄ±lÄ±!")
                    return response.text
                else:
                    print("âš ï¸ Gemini boÅŸ cevap dÃ¶ndÃ¼")
                    
            except Exception as e:
                print(f"âŒ Gemini API hatasÄ± (deneme {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2  # 2, 4, 6 saniye bekle
                    print(f"â³ {wait_time} saniye bekleniyor...")
                    time.sleep(wait_time)
                else:
                    # Son deneme baÅŸarÄ±sÄ±z olursa, fallback cevabÄ± ver
                    return create_fallback_response(query, related_chunks_with_metadata)
                    
    except Exception as e:
        print(f"âŒ Genel hata: {e}")
        return f"ÃœzgÃ¼nÃ¼m, cevap oluÅŸturulurken bir hata oluÅŸtu: {e}"

def create_fallback_response(query, chunks):
    """API baÅŸarÄ±sÄ±z olduÄŸunda basit cevap oluÅŸturur."""
    
    query_lower = query.lower()
    
    # Boyut sorularÄ± iÃ§in
    if any(w in query_lower for w in ['boyut', 'size', 'Ã¶lÃ§Ã¼', 'limit', 'sÄ±nÄ±r']):
        for chunk in chunks:
            if any(w in chunk['content'].lower() for w in ['18', '22', 'expansion']):
                return f"""2025-2026 Push Back oyununda robot boyut sÄ±nÄ±rlarÄ±:

â€¢ BaÅŸlangÄ±Ã§: 18" x 18" x 18" (maksimum)
â€¢ GeniÅŸleme: 22" x 22" x 22" (maksimum)

**Kaynak: Sayfa {chunk['page_number']}, Kural {chunk['rule_id']}**"""

    # AÄŸÄ±rlÄ±k sorularÄ± iÃ§in
    elif any(w in query_lower for w in ['aÄŸÄ±rlÄ±k', 'weight', 'gram']):
        for chunk in chunks:
            if '40' in chunk['content'] and 'gram' in chunk['content'].lower():
                return f"""2025-2026 Push Back oyununda:

â€¢ **Robot aÄŸÄ±rlÄ±k sÄ±nÄ±rÄ±:** BelirtilmemiÅŸ
â€¢ **Block aÄŸÄ±rlÄ±ÄŸÄ±:** YaklaÅŸÄ±k 40 gram

**Kaynak: Sayfa {chunk['page_number']}, Kural {chunk['rule_id']}**"""
    
    # Genel fallback
    return "API baÄŸlantÄ± sorunu nedeniyle tam cevap oluÅŸturulamadÄ±. LÃ¼tfen tekrar deneyin."

def answer_question(query):
    """
    Soru cevaplama iÃ§in ana fonksiyon wrapper'Ä±
    """
    return get_answer_from_gemini(query)

if __name__ == "__main__":
    # Test amaÃ§lÄ±
    test_query = "Robot aÄŸÄ±rlÄ±k sÄ±nÄ±rÄ± nedir?"
    answer = get_answer_from_gemini(test_query)
    print(f"Soru: {test_query}")
    print(f"Cevap: {answer}")